---
layout: default
categories: "DataScience"
permalink: /:categories/:title
title: "Project Scoping and Data Collection - Part 1 of 5"
---

# Project Scoping and Data Collection

In this 5 part walk-through, I'll demonstrate a simple Machine Learning project to build a classifier model.

First step which is Project Scoping and ETL(Extract, Transform, Load) or ELT(Extract, Load, Transform) consists of gathering our data into a usable, tabular format for the machine learning problem.
<!--end-excerpt-->

## Pre-Requisites
MiniConda (Python 3) with following libraries:

- xlrd
- numpy
- pandas
- seaborn
- scipy
- statsmodels
- scikit-learn
- ipykernel
- imbalanced-learn
- jupyterlab

## 1. Project Scope / Problem's literature review' conclusion
Dataset: 6 months of credit usage history for 30000 people.

Input Variables: Anonymized personal data and financial habits' data of each person (data-point).  
Target Variable: default_payment_next_month: True/False for if people defaulted on credit payment in the 7th month.

Problem Type: Classification
To train a model which can predict if a person will default on their credit payment or not.

#### Importing libraries

It's a good practice to only import what we need, even better to mention why. As the adage goes, one can discern the what and how from well-written code but not why, which is just as important.


```python
#data organizing
import pandas #storage
import numpy as np #data-type conversion
from os import getcwd #to get relative path so dataset may be easy and simple to find and load

#splitting the dataset - simple method
from sklearn.model_selection import train_test_split
```

## 2. Extract
This steps involves identifying the one or more data sources and from which we will build-up our dataset.  
In this case, the dataset is already available in an excel sheet so this step doesn't apply.

Dataset Source:  
Kaggle: [https://www.kaggle.com/uciml/default-of-credit-card-clients-dataset](https://www.kaggle.com/uciml/default-of-credit-card-clients-dataset)  
UCI: [https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients](https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients)

#### 2.1. Extract - Importing the dataset
Now, fetching the data.

API Docs: [Pandas DataFrame read_excel()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_excel.html)


```python
url = getcwd() + '\\default of credit card clients.xls'
ccd = pandas.read_excel(io = url, \
                        sheet_name='Data', header = 1, index_col = 0, \
                        dtype = {'LIMIT_BAL': np.int32, 'AGE': np.int32, 'BILL_AMT1': np.int32, 'BILL_AMT2': np.int32, 'BILL_AMT3': np.int32, 'BILL_AMT4': np.int32, 'BILL_AMT5': np.int32, 'BILL_AMT6': np.int32, 'PAY_AMT1': np.int32, 'PAY_AMT2': np.int32, 'PAY_AMT3': np.int32, 'PAY_AMT4': np.int32, 'PAY_AMT5': np.int32, 'PAY_AMT6': np.int32}, \
                        converters = {'SEX': cvSex, 'EDUCATION': cvEducation, 'MARRIAGE': cvMarriage, 'default payment next month': cvDefPay, 'PAY_0': cvPayHistory, 'PAY_2': cvPayHistory, 'PAY_3': cvPayHistory, 'PAY_4': cvPayHistory, 'PAY_5': cvPayHistory, 'PAY_6': cvPayHistory,})
```

__dtype__ changed from int64 to int32 to save space and speed up computation, however, while doing so, we should firstly know that there won't be any overflow or underflow of data.

__converters__ utilize the previously defined converter methods to transform categorical data into a better understandable format. It's not needed for solving the classification problem, but just to understand the data we are working with.

__converters__ won't be used while training the classification models since it's a mathematical process requiring both categorical and continuous variables to be encoded as numbers.

## 3. Transform
#### 3.1.Transform - Converters for categorical variables
Pre-defining converter methods (more on that below), using dictionaries to substitute for switch-case statements. Mappings have been taken from the dataset's description.

This is not a necessity but just so that it's easier to understand the dataset. 


```python
def cvSex(sex):
    mapper = {1: 'Male', 2: 'Female'}
    return mapper.get(sex)

def cvEducation(education):
    mapper = {1: 'Graduate', 2: 'University', 3: 'High School', 4: 'Others'}
    return mapper.get(education, 'Others') #takes care of cases 0, 5 and 6

def cvMarriage(marriage):
    mapper = {1: 'Married', 2: 'Single', 3: 'Divorced', 4: 'Others'}
    return mapper.get(marriage, 'Others') #takes care of 54 entries

def cvPayHistory(payHistory):
    mapper = {-2: 'No Credit Use', -1: 'Paid in Full', 0: 'Revolving Credit Used', 1: 'Delay 1 of month', 2: 'Delay 2 of months', 3: 'Delay 3 of months', 4: 'Delay 4 of months', 5: 'Delay 5 of months', 6: 'Delay 6 of months', 7: 'Delay 7 of months', 8: 'Delay 8 of months', 9: 'Delay 9 of months OR more'}
    return mapper.get(payHistory)


def cvDefPay(prediction):
    mapper = {0: False, 1: True}
    return mapper.get(prediction)
```

#### 3.2 Transform - Bringing variables' names upto convention

This step is only to bring the dataset's variables' name upto convention, if any aren't.

[Pandas DataFrame rename()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.rename.html)

In this case PAY started from 0 and had no PAY_1.

The target variable has it's spaces removed since spaces can cause issues with some libraries.


```python
ccd.rename(columns = {'PAY_0': 'PAY_1'}, inplace = True)
ccd.rename(columns = {'default payment next month': 'default_payment_next_month'}, inplace = True)
```

## 4. Load

This step involves saving/storing the cleaned, transformed dataset onto a persistent storage, so that we need not repeat this process.

This was a small example of ETL process at the beginning of the project. For this project, I'm not saving the ETL's output dataset.

As we gain more insight on the nature of the dataset and the problem we have to solve, ETL, especially transform process evolves.

<sup><sub>
Posted: 02nd September, 2020, 00:20 UTC+5:30  
</sub></sup>
