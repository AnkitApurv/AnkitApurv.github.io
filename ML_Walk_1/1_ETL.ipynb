{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "---\r\n",
    "layout: default\r\n",
    "categories: \"DataScience\"\r\n",
    "permalink: /:categories/:title\r\n",
    "title: \"ML Walk-through 1 - Part 1 of 5\"\r\n",
    "---"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Project Scoping and Data Collection\r\n",
    "\r\n",
    "In this 5 part walk-through, I'll demonstrate a simple Machine Learning project to build a classifier model.\r\n",
    "\r\n",
    "First step which is Project Scoping and ETL(Extract, Transform, Load) or ELT(Extract, Load, Transform) consists of gathering our data into a usable, tabular format for the machine learning problem.\r\n",
    "<!--end-excerpt-->\r\n",
    "\r\n",
    "ML Walk-through Series:\r\n",
    "\r\n",
    "1. Project Scoping and Data Collection\r\n",
    "2. Initial Model\r\n",
    "3. Exploratory Data Analysis\r\n",
    "4. Data Processing\r\n",
    "5. Final Model\r\n"
   ],
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {}
      }
     }
    },
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Pre-Requisites\n",
    "MiniConda (Python 3) with following libraries:\n",
    "  - xlrd\n",
    "  - numpy\n",
    "  - pandas\n",
    "  - seaborn\n",
    "  - scipy\n",
    "  - statsmodels\n",
    "  - scikit-learn\n",
    "  - ipykernel\n",
    "  - imbalanced-learn\n",
    "  - jupyterlab"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Project Scope / Problem's literature review' conclusion\r\n",
    "Dataset: 6 months of credit usage history for 30000 people.\r\n",
    "\r\n",
    "Input Variables: Anonymized personal data and financial habits' data of each person (data-point).  \r\n",
    "Target Variable: default_payment_next_month: True/False for if people defaulted on credit payment in the 7th month.\r\n",
    "\r\n",
    "Problem Type: Classification\r\n",
    "To train a model which can predict if a person will default on their credit payment or not."
   ],
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {}
      }
     }
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Importing libraries\r\n",
    "\r\n",
    "It's a good practice to only import what we need, even better to mention why. As the adage goes, one can discern the what and how from well-written code but not why, which is just as important."
   ],
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {}
      }
     }
    },
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "#data organizing\r\n",
    "import pandas #storage\r\n",
    "import numpy as np #data-type conversion\r\n",
    "from os import getcwd #to get relative path so dataset may be easy and simple to find and load\r\n",
    "\r\n",
    "#splitting the dataset - simple method\r\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "outputs": [],
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {}
      }
     }
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Extract\r\n",
    "This steps involves identifying the one or more data sources and from which we will build-up our dataset.  \r\n",
    "In this case, the dataset is already available in an excel sheet so this step doesn't apply.\r\n",
    "\r\n",
    "Dataset Source:  \r\n",
    "Kaggle: [https://www.kaggle.com/uciml/default-of-credit-card-clients-dataset](https://www.kaggle.com/uciml/default-of-credit-card-clients-dataset)  \r\n",
    "UCI: [https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients](https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients)"
   ],
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {}
      }
     }
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.1. Extract - Importing the dataset\r\n",
    "Now, fetching the data.\r\n",
    "\r\n",
    "API Docs: [Pandas DataFrame read_excel()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_excel.html)"
   ],
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {}
      }
     }
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "url = getcwd() + '\\\\default of credit card clients.xls'\r\n",
    "ccd = pandas.read_excel(io = url, \\\r\n",
    "                        sheet_name='Data', header = 1, index_col = 0, \\\r\n",
    "                        dtype = {'LIMIT_BAL': np.int32, 'AGE': np.int32, 'BILL_AMT1': np.int32, 'BILL_AMT2': np.int32, 'BILL_AMT3': np.int32, 'BILL_AMT4': np.int32, 'BILL_AMT5': np.int32, 'BILL_AMT6': np.int32, 'PAY_AMT1': np.int32, 'PAY_AMT2': np.int32, 'PAY_AMT3': np.int32, 'PAY_AMT4': np.int32, 'PAY_AMT5': np.int32, 'PAY_AMT6': np.int32}, \\\r\n",
    "                        converters = {'SEX': cvSex, 'EDUCATION': cvEducation, 'MARRIAGE': cvMarriage, 'default payment next month': cvDefPay, 'PAY_0': cvPayHistory, 'PAY_2': cvPayHistory, 'PAY_3': cvPayHistory, 'PAY_4': cvPayHistory, 'PAY_5': cvPayHistory, 'PAY_6': cvPayHistory,})"
   ],
   "outputs": [],
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {}
      }
     }
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "__dtype__ changed from int64 to int32 to save space and speed up computation, however, while doing so, we should firstly know that there won't be any overflow or underflow of data.\n",
    "\n",
    "__converters__ utilize the previously defined converter methods to transform categorical data into a better understandable format. It's not needed for solving the classification problem, but just to understand the data we are working with.\n",
    "\n",
    "__converters__ won't be used while training the classification models since it's a mathematical process requiring both categorical and continuous variables to be encoded as numbers."
   ],
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {}
      }
     }
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Transform\r\n",
    "#### 3.1.Transform - Converters for categorical variables\r\n",
    "Pre-defining converter methods (more on that below), using dictionaries to substitute for switch-case statements. Mappings have been taken from the dataset's description.\r\n",
    "\r\n",
    "This is not a necessity but just so that it's easier to understand the dataset. "
   ],
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {}
      }
     }
    },
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "def cvSex(sex):\r\n",
    "    mapper = {1: 'Male', 2: 'Female'}\r\n",
    "    return mapper.get(sex)\r\n",
    "\r\n",
    "def cvEducation(education):\r\n",
    "    mapper = {1: 'Graduate', 2: 'University', 3: 'High School', 4: 'Others'}\r\n",
    "    return mapper.get(education, 'Others') #takes care of cases 0, 5 and 6\r\n",
    "\r\n",
    "def cvMarriage(marriage):\r\n",
    "    mapper = {1: 'Married', 2: 'Single', 3: 'Divorced', 4: 'Others'}\r\n",
    "    return mapper.get(marriage, 'Others') #takes care of 54 entries\r\n",
    "\r\n",
    "def cvPayHistory(payHistory):\r\n",
    "    mapper = {-2: 'No Credit Use', -1: 'Paid in Full', 0: 'Revolving Credit Used', 1: 'Delay 1 of month', 2: 'Delay 2 of months', 3: 'Delay 3 of months', 4: 'Delay 4 of months', 5: 'Delay 5 of months', 6: 'Delay 6 of months', 7: 'Delay 7 of months', 8: 'Delay 8 of months', 9: 'Delay 9 of months OR more'}\r\n",
    "    return mapper.get(payHistory)\r\n",
    "\r\n",
    "\r\n",
    "def cvDefPay(prediction):\r\n",
    "    mapper = {0: False, 1: True}\r\n",
    "    return mapper.get(prediction)"
   ],
   "outputs": [],
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {}
      }
     }
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3.2 Transform - Bringing variables' names upto convention\r\n",
    "\r\n",
    "This step is only to bring the dataset's variables' name upto convention, if any aren't.\r\n",
    "\r\n",
    "[Pandas DataFrame rename()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.rename.html)\r\n",
    "\r\n",
    "In this case PAY started from 0 and had no PAY_1.\r\n",
    "\r\n",
    "The target variable has it's spaces removed since spaces can cause issues with some libraries."
   ],
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {}
      }
     }
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "ccd.rename(columns = {'PAY_0': 'PAY_1'}, inplace = True)\r\n",
    "ccd.rename(columns = {'default payment next month': 'default_payment_next_month'}, inplace = True)"
   ],
   "outputs": [],
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {}
      }
     }
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Load\r\n",
    "\r\n",
    "This step involves saving/storing the cleaned, transformed dataset onto a persistent storage, so that we need not repeat this process.\r\n",
    "\r\n",
    "This was a small example of ETL process at the beginning of the project. For this project, I'm not saving the ETL's output dataset.\r\n",
    "\r\n",
    "As we gain more insight on the nature of the dataset and the problem we have to solve, ETL, especially transform process evolves."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<sup><sub>\r\n",
    "Posted: 02nd September, 2020, 00:20 UTC+5:30  \r\n",
    "</sub></sup>"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "extensions": {
   "jupyter_dashboards": {
    "activeView": "grid_default",
    "version": 1,
    "views": {
     "grid_default": {
      "cellMargin": 10,
      "defaultCellHeight": 20,
      "maxColumns": 12,
      "name": "grid",
      "type": "grid"
     },
     "report_default": {
      "name": "report",
      "type": "report"
     }
    }
   }
  },
  "kernelspec": {
   "display_name": "Python [conda env:.conda-CreditDefaulterClassification]",
   "language": "python",
   "name": "conda-env-.conda-CreditDefaulterClassification-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}